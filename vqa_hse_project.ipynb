{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5n1Tv-MkIL1"
   },
   "source": [
    "# **Импорты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWZQu34YVqB6",
    "outputId": "873b16c9-93b5-4a97-ad28-da49d682640d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
      "Collecting ruff\n",
      "  Downloading ruff-0.4.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.45.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Installing collected packages: ruff\n",
      "Successfully installed ruff-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb ruff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "n66rBgE_wKIc",
    "outputId": "f68f2eff-4125-463b-9725-a251bc4e880c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "userdata.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rcU6OnmVTtcT"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# для теста\n",
    "# from datasets import load_dataset\n",
    "\n",
    "from torch.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nS4y6PUEt1_o"
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-EBBYC8azyM"
   },
   "source": [
    "# **Датасет - чек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-DuCuKUuHMQ"
   },
   "outputs": [],
   "source": [
    "train_data = load_dataset(\"SirNeural/flan_v2\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7Z3yr27UcIk",
    "outputId": "ed527381-7e49-4a4f-9c96-715f72f4dfdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [05:02<00:00, 330.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[   2,    5, 1532,  ..., 4370, 2461,    3]]),\n",
       " tensor([[   2,    5, 1532,  ...,    0,    0,    0]]),\n",
       " tensor([[    2,     5, 10126,  ...,     5,   207,     3]]),\n",
       " tensor([[   2, 6330,  244,  ..., 2864,    5,    3]]),\n",
       " tensor([[   2,    5, 1532,  ...,    0,    0,    0]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = []\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    inputs = train_data[i][\"inputs\"]\n",
    "    targets = train_data[i][\"targets\"]\n",
    "\n",
    "    train_row = f\"{inputs}, {targets}, {tokenizer.eos_token}\"\n",
    "    embeded_row = tokenizer.encode(\n",
    "        train_row,\n",
    "        padding=\"max_length\",\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    emb += [embeded_row]\n",
    "emb[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJ8hzbOpYiv-",
    "outputId": "a45b2ca7-722a-47e7-de1d-0d1c134e5136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30000, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fnw7BIBlXVcn"
   },
   "outputs": [],
   "source": [
    "emb_dataset = torch.utils.data.ConcatDataset([emb])\n",
    "train_dataset = DataLoader(emb_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWYxLxHQCXzY"
   },
   "source": [
    "# **LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBlSCxTnCW7B"
   },
   "outputs": [],
   "source": [
    "checkpoint = \"EleutherAI/pythia-1b\"\n",
    "tok = AutoTokenizer.from_pretrained(checkpoint)\n",
    "mod = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDxsfcyuVPIc"
   },
   "outputs": [],
   "source": [
    "class EMA(nn.Module):\n",
    "    def __init__(self, decay: float):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "        self.shadow_params = {}\n",
    "\n",
    "    def forward(self, model: nn.Module):\n",
    "        for name, params in model.named_parameters():\n",
    "            if params.requires_grad:\n",
    "                if name not in self.shadow_params:\n",
    "                    self.shadow_params[name] = params.data.clone()\n",
    "                else:\n",
    "                    # shadow_variable -= (1 - decay) * (shadow_variable - variable)\n",
    "                    self.shadow_params[name] -= (1 - self.decay) * (\n",
    "                        self.shadow_params[name] - params\n",
    "                    )\n",
    "                params.data = self.shadow_params[name]\n",
    "\n",
    "\n",
    "ema = EMA(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQ7Jb5TSY08v"
   },
   "outputs": [],
   "source": [
    "def freeze(model: nn.Module):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MC0eCxURTMVi"
   },
   "outputs": [],
   "source": [
    "training_steps = 1000\n",
    "optimizer = AdamW(mod.parameters())\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=training_steps // 10, num_training_steps=training_steps\n",
    ")\n",
    "\n",
    "wandb.login(key=userdata.get(\"WANDB_KEY\"), relogin=True)\n",
    "wandb.init(sync_tensorboard=True, name=\"test\", project=\"hse-project\", entity=\"aid_\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "mod.to(device)\n",
    "\n",
    "freeze(mod)\n",
    "\n",
    "\n",
    "def one_epoch(model, data):\n",
    "    model.train()\n",
    "\n",
    "    for batch in data:\n",
    "        batch = batch.view(batch.shape[0], batch.shape[-1])\n",
    "\n",
    "        t = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            loss = model(input_ids=t, labels=t)[\"loss\"]\n",
    "            wandb.log({\"loss\": loss})\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # ema(model)\n",
    "\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSGphOeZqUdI"
   },
   "source": [
    "# **Experiments with diff LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MX6x4t4GqdiY"
   },
   "source": [
    "**Gemma-2b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "0e74351be76645a2bfb103ba79d48c4a",
      "663b614f801b454fa8ff8dde530f1212",
      "3a1d52d8f5174d49854b6d611cd205d8",
      "2da3d63f2084458e969a7e0a44c5eacc",
      "e080a232c77e4523bce64efd9b9dd903",
      "036d3b5d57324924853212c8c4a15f63",
      "1f5cb3f38ce94d5bb1d90105970428f5",
      "c94f4a84d5154d8689dfc74e6caf39de",
      "f77c1051e90c4e8f81ce14e8989c23be",
      "30df5202627f4638b76e992744403efa",
      "cd6ec1713eb04fcc8c4fd3274261dbab"
     ]
    },
    "id": "i54-4Z2QqcPH",
    "outputId": "17039827-b3ab-4c2d-eea0-d16c6ff04f20"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e74351be76645a2bfb103ba79d48c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write me a poem about Machine Learning.\n",
      "\n",
      "I’m not sure what you mean by “\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"google/gemma-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "\n",
    "input_text = \"Какого .\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**input_ids)\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "\n",
    "del tokenizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tXGqOYlvUgA"
   },
   "source": [
    "**Phi-1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XkgX57yuYaJ",
    "outputId": "381cb5e2-2fd4-4041-ae78-c9855cc30b99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[2437,  867, 7405,  857,  257, 8223,  423,   30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[ 2437,   867,  7405,   857,   257,  8223,   423,    30,   198, 33706,\n",
      "            25,   317,  8223,   468,  1440,  7405,    13,   198,   198,  3109,\n",
      "         23697,   513,    25,  1867,   318,   262,  4007,   286,   257,  8223,\n",
      "           338,  7894,    30,   198, 33706,    25,   317,  8223,   338,  7894]])\n",
      "How many legs does a horse have?\n",
      "Answer: A horse has four legs.\n",
      "\n",
      "Exercise 3: What is the purpose of a horse's tail?\n",
      "Answer: A horse's tail\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"microsoft/phi-1_5\"\n",
    "\n",
    "# config = AutoConfig.from_pretrained(checkpoint, max_new_tokens = 128)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "\n",
    "input_text = \"How many legs does a horse have?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "print(input_ids)\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=32)\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mDqW1R110e8M"
   },
   "outputs": [],
   "source": [
    "rus_inp_text = \"Какого цвета небо?\"\n",
    "rus_ids = tokenizer(rus_inp_text, return_tensors=\"pt\")\n",
    "rus_out = model.generate(**rus_ids, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-y48Bi6t4Cht",
    "outputId": "7b317422-bd51-4644-ef36-97e3f75e4757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какого цвета небо?\n",
      "    # Проверка не принимается в простоте\n",
      "    if not is_valid_number(number):\n",
      "        raise ValueError(\"Invalid number\")\n",
      "\n",
      "    # Проверка не принимается в простоте\n",
      "    if not is_valid_number(number, 2):\n",
      "        raise ValueError(\"Invalid number\")\n",
      "\n",
      "    # Проверка не принимается в простоте\n",
      "    if not is_valid_number(number, 3):\n",
      "        raise ValueError(\"Invalid number\")\n",
      "\n",
      "    # Проверка не принимается в простоте\n",
      "    if not is_valid_number(number, 4):\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(rus_out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LxOlr1NH6PW9"
   },
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGBLmCNU6IgK"
   },
   "source": [
    "# **Image encoders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lewj3NE6M-2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "v-EBBYC8azyM",
    "HWYxLxHQCXzY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "036d3b5d57324924853212c8c4a15f63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e74351be76645a2bfb103ba79d48c4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_663b614f801b454fa8ff8dde530f1212",
       "IPY_MODEL_3a1d52d8f5174d49854b6d611cd205d8",
       "IPY_MODEL_2da3d63f2084458e969a7e0a44c5eacc"
      ],
      "layout": "IPY_MODEL_e080a232c77e4523bce64efd9b9dd903"
     }
    },
    "1f5cb3f38ce94d5bb1d90105970428f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2da3d63f2084458e969a7e0a44c5eacc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30df5202627f4638b76e992744403efa",
      "placeholder": "​",
      "style": "IPY_MODEL_cd6ec1713eb04fcc8c4fd3274261dbab",
      "value": " 2/2 [00:23&lt;00:00,  9.83s/it]"
     }
    },
    "30df5202627f4638b76e992744403efa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a1d52d8f5174d49854b6d611cd205d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c94f4a84d5154d8689dfc74e6caf39de",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f77c1051e90c4e8f81ce14e8989c23be",
      "value": 2
     }
    },
    "663b614f801b454fa8ff8dde530f1212": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_036d3b5d57324924853212c8c4a15f63",
      "placeholder": "​",
      "style": "IPY_MODEL_1f5cb3f38ce94d5bb1d90105970428f5",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "c94f4a84d5154d8689dfc74e6caf39de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd6ec1713eb04fcc8c4fd3274261dbab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e080a232c77e4523bce64efd9b9dd903": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f77c1051e90c4e8f81ce14e8989c23be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}