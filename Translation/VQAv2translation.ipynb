{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ypNgSd4_jlI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n",
        "!pip install datasets\n",
        "!pip install jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from datasets import load_dataset\n",
        "import torch"
      ],
      "metadata": {
        "id": "bEiXCzQkAVRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VQAv2_train = load_dataset(\"HuggingFaceM4/VQAv2\", split=\"train\").remove_columns(['question_type', 'answers', 'answer_type', 'question_id', 'image'])\n",
        "\n",
        "VQAv2_val = load_dataset(\"HuggingFaceM4/VQAv2\", split=\"val\").remove_columns(['question_type', 'answers', 'answer_type', 'question_id', 'image'])"
      ],
      "metadata": {
        "id": "J9fGvjSxQoNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_img_format(img_id):\n",
        "  return f\"COCO_train2014_{img_id:012d}\"\n",
        "\n",
        "def val_img_format(img_id):\n",
        "  return f\"COCO_val2014_{img_id:012d}\""
      ],
      "metadata": {
        "id": "AZZWk6wc_pTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VQAv2_train\n",
        "image_id_train = []\n",
        "answer_train = []\n",
        "question_train = []\n",
        "\n",
        "for feature in tqdm(VQAv2_train):\n",
        "    if len(feature[\"multiple_choice_answer\"]) <= 500 and len(feature[\"question\"]) <= 500:\n",
        "\n",
        "        answer_train.append(feature[\"multiple_choice_answer\"])\n",
        "        image = train_img_format(feature[\"image_id\"])\n",
        "        image_id_train.append(image)\n",
        "        question_train.append(feature[\"question\"])"
      ],
      "metadata": {
        "id": "74-lJhRfdMX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VQAv2_val\n",
        "image_id_val = []\n",
        "answer_val = []\n",
        "question_val = []\n",
        "\n",
        "for feature in tqdm(VQAv2_val):\n",
        "    if len(feature[\"multiple_choice_answer\"]) <= 500 and len(feature[\"question\"]) <= 500:\n",
        "\n",
        "        answer_val.append(feature[\"multiple_choice_answer\"])\n",
        "        image = val_img_format(feature[\"image_id\"])\n",
        "        image_id_val.append(image)\n",
        "        question_val.append(feature[\"question\"])"
      ],
      "metadata": {
        "id": "FLYSWV99P1XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "def translation(model, tokenizer, sentences, batch_size):\n",
        "    sentences_ru = []\n",
        "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(sentences), batch_size)):\n",
        "            batch = sentences[i: i + batch_size]\n",
        "\n",
        "            input_ids = tokenizer.batch_encode_plus(batch, padding=\"max_length\", max_length=512, return_tensors=\"pt\", truncation=True)[\"input_ids\"].to(device)\n",
        "            generated_tokens = model.generate(input_ids, max_length=512, forced_bos_token_id=tokenizer.lang_code_to_id[\"rus_Cyrl\"])\n",
        "            output_ids = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "            sentences_ru = sentences_ru + output_ids\n",
        "\n",
        "    return sentences_ru"
      ],
      "metadata": {
        "id": "ojVgKwvvdPb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"facebook/nllb-200-distilled-600M\"\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint).to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "RqywKGGydSGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 200\n",
        "\n",
        "# VQAv2_train\n",
        "questions_train_ru = translation(model, tokenizer, question_train, batch_size)\n",
        "answers_train_ru = translation(model, tokenizer, answer_train, batch_size)"
      ],
      "metadata": {
        "id": "AN0qdaAvdUs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VQAv2_val\n",
        "questions_val_ru = translation(model, tokenizer, question_val, batch_size)\n",
        "answers_val_ru = translation(model, tokenizer, answer_val, batch_size)"
      ],
      "metadata": {
        "id": "0nbZVY3DQ-yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VQAv2_train\n",
        "questions_train = [i for i in questions_train_ru]\n",
        "answers_train = [i for i in answers_train_ru]\n",
        "max_len_train = len(question_train)"
      ],
      "metadata": {
        "id": "VcbqX6SidYLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VQAv2_val\n",
        "questions_val = [i for i in questions_val_ru]\n",
        "answers_val = [i for i in answers_val_ru]\n",
        "max_len_val = len(questions_val)"
      ],
      "metadata": {
        "id": "lfpj1L6IRQ-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_train = [{'image_id' : image_id_train[i], 'question' : questions_train[i], 'answer' : answers_train[i]} for i in range(max_len_train)]"
      ],
      "metadata": {
        "id": "anZq8qNxdajv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_val = [{'image_id' : image_id_val[i], 'question' : questions_val[i], 'answer' : answers_val[i]} for i in range(max_len_val)]"
      ],
      "metadata": {
        "id": "hQlbfMhbReeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jsonlines\n",
        "\n",
        "with jsonlines.open('VQAv2_train_translation.jsonl', mode='w') as writer:\n",
        "  writer.write(result_train)"
      ],
      "metadata": {
        "id": "jz243QjIdega"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('VQAv2_val_translation.jsonl', mode='w') as writer:\n",
        "  writer.write(result_val)"
      ],
      "metadata": {
        "id": "ZAnWo-L0RyOl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}